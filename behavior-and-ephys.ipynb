{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will explore both behavioral data (facial features)\n",
    "synchronized with electrical stimulation. There are two mice, R27 and R28, that\n",
    "have been implanted with a probe targeting the facial nucleus in each hemisphere.\n",
    "The mice are anesthesized, then stimulated at varying current amplitudes.\n",
    "Each stimulation setting is repeated several times within a single recording.\n",
    "For a given recording, we might either stimulate all electrodes on the probe,\n",
    "or a subset of electrodes to perform location-specific stimulation.\n",
    "\n",
    "Below, we define some global variables to store experimental metadata.\n",
    "- `CRANIOTOMY_MAP` maps from mouse name to which side the probe is implanted.\n",
    "- `STIM_PROTOCOL` maps from `(date, mouse, recording number)` to\n",
    "  `(stimulation amplitude, stimulation location)` where the location is a code:\n",
    "  - `AS`: all electrodes\n",
    "  - `1U`: first shank upper half\n",
    "  - `1L`: first shank lower half\n",
    "  - `2U`: second shank upper half\n",
    "  - `2L`: second shank lower half\n",
    "  - `3U`: third shank upper half\n",
    "  - `3L`: third shank lower half\n",
    "  - `4U`: fourth shank upper half\n",
    "  - `4L`: fourth shank lower half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRANIOTOMY_MAP = {\n",
    "    \"R27\": \"left\",\n",
    "    \"R28\": \"right\"\n",
    "}\n",
    "STIM_PROTOCOL = {\n",
    "    # R27 - 20240903\n",
    "    (\"20240903\", \"R27\", \"000\"): (1, 'AS'),\n",
    "    (\"20240903\", \"R27\", \"001\"): (2, 'AS'),\n",
    "    (\"20240903\", \"R27\", \"002\"): (5, 'AS'),\n",
    "    (\"20240903\", \"R27\", \"003\"): (10, 'AS'),\n",
    "    (\"20240903\", \"R27\", \"004\"): (0.5, 'AS'),\n",
    "    (\"20240903\", \"R27\", \"005\"): (0.25, 'AS'),\n",
    "    (\"20240903\", \"R27\", \"006\"): (0.1, 'AS'),\n",
    "    (\"20240903\", \"R27\", \"007\"): (1, '1U'),\n",
    "    (\"20240903\", \"R27\", \"008\"): (2, '1U'),\n",
    "    (\"20240903\", \"R27\", \"009\"): (5, '1U'),\n",
    "    (\"20240903\", \"R27\", \"010\"): (7.5, '1U'),\n",
    "    (\"20240903\", \"R27\", \"011\"): (10, '1U'),\n",
    "    (\"20240903\", \"R27\", \"012\"): (1, '1L'),\n",
    "    (\"20240903\", \"R27\", \"013\"): (2, '1L'),\n",
    "    (\"20240903\", \"R27\", \"014\"): (5, '1L'),\n",
    "    (\"20240903\", \"R27\", \"015\"): (7.5, '1L'),\n",
    "    (\"20240903\", \"R27\", \"016\"): (10, '1L'),\n",
    "    (\"20240903\", \"R27\", \"017\"): (1, '2U'),\n",
    "    (\"20240903\", \"R27\", \"018\"): (2, '2U'),\n",
    "    (\"20240903\", \"R27\", \"019\"): (5, '2U'),\n",
    "    # (\"20240903\", \"R27\", \"020\"): (None, None),\n",
    "    (\"20240903\", \"R27\", \"021\"): (7.5, '2U'),\n",
    "    (\"20240903\", \"R27\", \"022\"): (10, '2U'),\n",
    "    (\"20240903\", \"R27\", \"023\"): (1, '2L'),\n",
    "    (\"20240903\", \"R27\", \"024\"): (2, '2L'),\n",
    "    (\"20240903\", \"R27\", \"025\"): (5, '5L'),\n",
    "    (\"20240903\", \"R27\", \"026\"): (7.5, '2L'),\n",
    "    (\"20240903\", \"R27\", \"027\"): (10, '2L'),\n",
    "    (\"20240903\", \"R27\", \"028\"): (1, '3U'),\n",
    "    (\"20240903\", \"R27\", \"029\"): (2, '3U'),\n",
    "    (\"20240903\", \"R27\", \"030\"): (5, '3U'),\n",
    "    (\"20240903\", \"R27\", \"031\"): (7.5, '3U'),\n",
    "    (\"20240903\", \"R27\", \"032\"): (10, '3U'),\n",
    "    (\"20240903\", \"R27\", \"033\"): (1, '3L'),\n",
    "    (\"20240903\", \"R27\", \"034\"): (2, '3L'),\n",
    "    (\"20240903\", \"R27\", \"035\"): (5, '3L'),\n",
    "    (\"20240903\", \"R27\", \"036\"): (7.5, '3L'),\n",
    "    (\"20240903\", \"R27\", \"037\"): (10, '3L'),\n",
    "    (\"20240903\", \"R27\", \"038\"): (1, '4U'),\n",
    "    (\"20240903\", \"R27\", \"039\"): (2, '4U'),\n",
    "    (\"20240903\", \"R27\", \"040\"): (5, '4U'),\n",
    "    # (\"20240903\", \"R27\", \"041\"): (None, None),\n",
    "    (\"20240903\", \"R27\", \"042\"): (7.5, '4U'),\n",
    "    (\"20240903\", \"R27\", \"043\"): (10, '4U'),\n",
    "    (\"20240903\", \"R27\", \"044\"): (1, '4L'),\n",
    "    (\"20240903\", \"R27\", \"045\"): (2, '4L'),\n",
    "    (\"20240903\", \"R27\", \"046\"): (5, '4L'),\n",
    "    (\"20240903\", \"R27\", \"047\"): (7.5, '4L'),\n",
    "    (\"20240903\", \"R27\", \"048\"): (10, '4L'),\n",
    "    # R28 - 20240916\n",
    "    (\"20240916\", \"R28\", \"000\"): (1, \"AS\"),\n",
    "    (\"20240916\", \"R28\", \"001\"): (2, \"AS\"),\n",
    "    (\"20240916\", \"R28\", \"002\"): (5, \"AS\"),\n",
    "    (\"20240916\", \"R28\", \"003\"): (10, \"AS\"),\n",
    "    (\"20240916\", \"R28\", \"004\"): (0.5, \"AS\"),\n",
    "    (\"20240916\", \"R28\", \"005\"): (0.25, \"AS\"),\n",
    "    (\"20240916\", \"R28\", \"006\"): (0.1, \"AS\"),\n",
    "    (\"20240916\", \"R28\", \"007\"): (1, \"1U\"),\n",
    "    (\"20240916\", \"R28\", \"008\"): (2, \"1U\"),\n",
    "    (\"20240916\", \"R28\", \"009\"): (5, \"1U\"),\n",
    "    (\"20240916\", \"R28\", \"010\"): (7.5, \"1U\"),\n",
    "    (\"20240916\", \"R28\", \"011\"): (10, \"1U\"),\n",
    "    (\"20240916\", \"R28\", \"012\"): (1, \"1L\"),\n",
    "    (\"20240916\", \"R28\", \"013\"): (2, \"1L\"),\n",
    "    (\"20240916\", \"R28\", \"014\"): (5, \"1L\"),\n",
    "    (\"20240916\", \"R28\", \"015\"): (7.5, \"1L\"),\n",
    "    (\"20240916\", \"R28\", \"016\"): (10, \"1L\"),\n",
    "    (\"20240916\", \"R28\", \"017\"): (1, \"2U\"),\n",
    "    (\"20240916\", \"R28\", \"018\"): (2, \"2U\"),\n",
    "    # (\"20240916\", \"R28\", \"019\"): (5, \"2U\"),\n",
    "    (\"20240916\", \"R28\", \"020\"): (5, \"2U\"),\n",
    "    (\"20240916\", \"R28\", \"021\"): (7.5, \"2U\"),\n",
    "    (\"20240916\", \"R28\", \"022\"): (10, \"2U\"),\n",
    "    (\"20240916\", \"R28\", \"023\"): (1, \"2L\"),\n",
    "    (\"20240916\", \"R28\", \"024\"): (2, \"2L\"),\n",
    "    # (\"20240916\", \"R28\", \"025\"): (5, \"2L\"),\n",
    "    (\"20240916\", \"R28\", \"026\"): (5, \"2L\"),\n",
    "    (\"20240916\", \"R28\", \"027\"): (7.5, \"2L\"),\n",
    "    (\"20240916\", \"R28\", \"028\"): (10, \"2L\"),\n",
    "    (\"20240916\", \"R28\", \"029\"): (1, \"3U\"),\n",
    "    (\"20240916\", \"R28\", \"030\"): (2, \"3U\"),\n",
    "    (\"20240916\", \"R28\", \"031\"): (5, \"3U\"),\n",
    "    (\"20240916\", \"R28\", \"032\"): (7.5, \"3U\"),\n",
    "    (\"20240916\", \"R28\", \"033\"): (10, \"3U\"),\n",
    "    (\"20240916\", \"R28\", \"034\"): (1, \"3L\"),\n",
    "    (\"20240916\", \"R28\", \"035\"): (2, \"3L\"),\n",
    "    (\"20240916\", \"R28\", \"036\"): (5, \"3L\"),\n",
    "    (\"20240916\", \"R28\", \"037\"): (7.5, \"3L\"),\n",
    "    (\"20240916\", \"R28\", \"038\"): (10, \"3L\"),\n",
    "    (\"20240916\", \"R28\", \"039\"): (1, \"4U\"),\n",
    "    (\"20240916\", \"R28\", \"040\"): (2, \"4U\"),\n",
    "    (\"20240916\", \"R28\", \"041\"): (5, \"4U\"),\n",
    "    (\"20240916\", \"R28\", \"042\"): (7.5, \"4U\"),\n",
    "    (\"20240916\", \"R28\", \"043\"): (10, \"4U\"),\n",
    "    (\"20240916\", \"R28\", \"044\"): (1, \"4L\"),\n",
    "    (\"20240916\", \"R28\", \"045\"): (2, \"4L\"),\n",
    "    (\"20240916\", \"R28\", \"046\"): (5, \"4L\"),\n",
    "    (\"20240916\", \"R28\", \"047\"): (7.5, \"4L\"),\n",
    "    (\"20240916\", \"R28\", \"048\"): (10, \"4L\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we import some packages and utility functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from projectlib.utils import read_3d_data, sns_setup, VideoFrames\n",
    "from projectlib.anatomy import compute_measurements_df\n",
    "\n",
    "sns_setup(font=\"sans-serif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we read in the behavioral data.\n",
    "This is stored in `anipose-data/202408-ephys-all`, with a separate sub-folder\n",
    "for each recording. We build a dictionary that maps from `(date, mouse, recording)`\n",
    "to the CSV data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANIPOSE_BASE = \"anipose-data/202408-ephys-all\"\n",
    "COORDINATE_PATHS = {}\n",
    "key_cols = (\"date\", \"mouse\", \"run\")\n",
    "for p in Path(ANIPOSE_BASE).glob('*/pose-3d/*.csv'):\n",
    "    date, mouse, *_, run, _ = p.name.split(\"_\")\n",
    "    if (date, mouse, run) not in STIM_PROTOCOL.keys():\n",
    "        continue\n",
    "    COORDINATE_PATHS[(date, mouse, run)] = p\n",
    "data_keys = list(COORDINATE_PATHS.keys())\n",
    "data_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we read in the behavioral data and compute various geometrical features\n",
    "from the raw keypoint data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_data = {k: read_3d_data(v.parent.parent.as_posix())\n",
    "              for k, v in COORDINATE_PATHS.items()}\n",
    "\n",
    "meas_df = compute_measurements_df(coord_data, key_columns=key_cols)\n",
    "meas_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To synchronize the behavioral data with our stimulations, we need a signal that\n",
    "indicates when a stimulation was performed.\n",
    "Fortunately, the videos contain an LED that turns on whenever stimulation is on.\n",
    "In the code below, we\n",
    "1. Define `BBOX` which is a bounding box in pixels around the LED\n",
    "2. Read in the video file using the `VideoFrames` class\n",
    "3. Iterate over the frames and measure the average brightness in bounding box\n",
    "4. Threshold the brightness signal whenever it reachs 90% of its peak brightness\n",
    "5. Plot the resulting binary signal to verify that we can extract stimulation times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BBOX = (420, 430, 10, 20)\n",
    "\n",
    "def load_video_stim(path, bbox):\n",
    "    # get VideoFrames object\n",
    "    video = VideoFrames(path, bounds=bbox)\n",
    "    # get average brightness level\n",
    "    brightness = []\n",
    "    for frame in video:\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        brightness.append(np.mean(frame))\n",
    "    # normalize brightness level\n",
    "    brightness = np.asarray(brightness)\n",
    "    peak_brightness = np.max(brightness)\n",
    "    # threshold brightness\n",
    "    led_threshold = 0.9 * peak_brightness\n",
    "    led_signal = np.where(brightness > led_threshold, 1, 0)\n",
    "\n",
    "    return led_signal\n",
    "\n",
    "led = load_video_stim(\"fe-data/20240903_R27_recording_rig1/20240903_R27_recording_anes_000_BC_15-32-47.avi\",\n",
    "                      BBOX)\n",
    "plt.plot(led)\n",
    "plt.xlabel(\"Time (frames)\")\n",
    "plt.ylabel(\"LED signal\")\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we use the utility defined above to build up a `DataFrame` with the\n",
    "stimulation location, amplitude, and times for each recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ephys_df_led(data_keys, craniotomy, run_map, bbox):\n",
    "    df = []\n",
    "    # loop over all recordings\n",
    "    for date, mouse, run in tqdm(data_keys):\n",
    "        # get the implantation side for this mouse\n",
    "        craniotomy_side = craniotomy[mouse]\n",
    "        # get the stimulation parameters for this recording\n",
    "        stim_amp, stim_loc = run_map[(date, mouse, run)]\n",
    "        # break apart the stimulation location code into\n",
    "        # stimulation shank (1, 2, 3, 4) and stimulation depth (U, L)\n",
    "        if stim_loc == \"AS\":\n",
    "            stim_shank = \"A\"\n",
    "            stim_depth = \"A\"\n",
    "        else:\n",
    "            stim_shank, stim_depth = stim_loc\n",
    "        # use our utility to read in the LED signal\n",
    "        # take the path to the CSV file and find the corresponding video file\n",
    "        # (see the anipose-data folder to understand why this works)\n",
    "        csv_path = COORDINATE_PATHS[(date, mouse, run)]\n",
    "        fname_parts = csv_path.name.split(\"_\")\n",
    "        stim_vid = \"_\".join(fname_parts[:-1]) + \"_BC_\" + fname_parts[-1]\n",
    "        stim_vid = stim_vid.replace(\".csv\", \".avi\")\n",
    "        stim_vid = csv_path.parent.parent.joinpath(f\"videos-raw/{stim_vid}\")\n",
    "        stim_signal = load_video_stim(str(stim_vid), bbox)\n",
    "        # find the stimulation times based on the rising edge of the LED signal\n",
    "        # convert stimulation times from frames to seconds by dividing the FPS = 100\n",
    "        stim_times = np.where((stim_signal[1:] - stim_signal[:-1]) > 0)[0] / 100.0\n",
    "        # add this recording to the list of rows in the dataframe\n",
    "        df.append([date, mouse, run,\n",
    "                   stim_amp, len(stim_times),\n",
    "                   stim_shank, stim_depth, craniotomy_side,\n",
    "                   stim_signal, stim_times,\n",
    "                   0.0, 100.0, 0.0])\n",
    "\n",
    "    # create a dataframe object from the rows\n",
    "    df = pd.DataFrame(df, columns=[*key_cols,\n",
    "                                   \"stim_amplitude\", \"nrepeats\",\n",
    "                                   \"stim_shank\", \"stim_depth\", \"stim_side\",\n",
    "                                   \"stim_signal\", \"stim_times\",\n",
    "                                   \"lag_time\", \"sample_rate\", \"lag_slope\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "ephys_df = build_ephys_df_led(data_keys, CRANIOTOMY_MAP, STIM_PROTOCOL, BBOX)\n",
    "ephys_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make our lives easier, we will combine the behavioral and stimulation `DataFrames`s.\n",
    "There are many rows in the behavioral data corresponding to a single row in the\n",
    "stimulation data, because for each recording we have multiple facial features that we measure.\n",
    "So, we use a utility to select the matching stimulation data row for each row\n",
    "of the behavioral data, then concatenate the columns together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _select_ephys_row(row):\n",
    "    ephys_row = ephys_df.query(\"date == @row.date & \"\n",
    "                               \"mouse == @row.mouse & \"\n",
    "                               \"run == @row.run\")\n",
    "\n",
    "    return ephys_row[[\"stim_amplitude\",\n",
    "                      \"nrepeats\",\n",
    "                      \"stim_shank\",\n",
    "                      \"stim_depth\",\n",
    "                      \"stim_side\",\n",
    "                      \"stim_times\"]].squeeze()\n",
    "\n",
    "merge_df = pd.concat([meas_df, meas_df.apply(_select_ephys_row, axis=1)], axis=1)\n",
    "merge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the data. We will query our `DataFrame` for a specific date,\n",
    "mouse, and facial measurement. We will also focus on only all electrode stimulation\n",
    "so that everything is fairly comparable.\n",
    "Next, we will use `seaborn.FacetGrid` to generate a grid of plots, one for each\n",
    "stimulation amplitude, and plot the facial measurement signal aligned to each stimulation.\n",
    "\n",
    "We've written the code in `plot_helper` to plot all the raw traces.\n",
    "**_You should fill in the TODO section with additional plotting to show the mean\n",
    "signal across all stimulations._**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility to convert an array of times in seconds to frames\n",
    "def _time_to_frame(ts):\n",
    "    return np.floor(ts * 100).astype(int)\n",
    "\n",
    "# this function is a plotting utility that we pass to FacetGrid.map\n",
    "# it is responsible for plotting what goes in each subplot of the grid\n",
    "# it receives Pandas Series as arguments corresponding to the columns of our DataFrame\n",
    "def plot_helper(stim_times, timeseries, color):\n",
    "    # there should be only a single row in our Series objects\n",
    "    # which is why you see XXXX.values[0]\n",
    "    # convert stimulation times to frames\n",
    "    stim_times = _time_to_frame(stim_times.values[0])\n",
    "    # get the facial feature timeseries\n",
    "    timeseries = timeseries.values[0]\n",
    "    # define the window around each stimulation\n",
    "    t_prestim = int(0.1 * 100) # 0.1 seconds before stim\n",
    "    t_poststim = int(0.4 * 100) # 0.4 seconds after stim\n",
    "    # for each stimulation time, read in the signal in a window around\n",
    "    # that time point\n",
    "    # this builds up a list of timeseries where each item in the list\n",
    "    # corresponds to a single stimulation\n",
    "    ys = [timeseries[(t - t_prestim):(t + t_poststim)] for t in stim_times]\n",
    "    # define the time axis for each timeseries in the list where\n",
    "    # t = 0 is the time of stimulation\n",
    "    xs = [(np.arange(len(y)) - t_prestim) / 100 for y in ys]\n",
    "    # for each stimulation in the list, plot the behavioral signal\n",
    "    for x, y in zip(xs, ys):\n",
    "        sns.lineplot(x=x, y=y, color=color, alpha=0.3, linewidth=1.25)\n",
    "    # TODO: add code to plot the mean behavioral signal across all\n",
    "    # stimulations in the list\n",
    "    # ADD YOUR CODE HERE\n",
    "    # plot the time of stimulation as a vertical dashed line\n",
    "    plt.axvline(0, color=\"black\", linestyle=\"dashed\", linewidth=2)\n",
    "\n",
    "# query the data for a specific date, mouse, stimulation location, and measurement\n",
    "sub_df = merge_df.query(\"date == '20240916' & mouse == 'R28' & \"\n",
    "                        \"stim_shank == 'A' & stim_depth == 'A' & \"\n",
    "                        \"measurement_name == 'eye-height-right'\")\n",
    "# create a grid of plots where the columns of the grid correspond\n",
    "# to different values of the stimulation amplitude column in the data\n",
    "g = sns.FacetGrid(sub_df,\n",
    "                  col=\"stim_amplitude\",\n",
    "                  col_order=sub_df[\"stim_amplitude\"].unique().sort(),\n",
    "                  sharey=True,\n",
    "                  aspect=1,\n",
    "                  margin_titles=True)\n",
    "# plot the data in the grid using our helper utility\n",
    "g.map(plot_helper, \"stim_times\", \"timeseries\")\n",
    "g.figure.suptitle(\"Example change of eye height to varying stimulation amplitudes\", y=1.05)\n",
    "g.set_titles(col_template=\"{col_name} $\\mu$A\")\n",
    "g.set_xlabels(\"Time from stimulation (sec)\")\n",
    "g.set_ylabels(\"Right eye height (mm)\")\n",
    "sns.despine(g.figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We see that as the stimulation amplitude increases, the right eye height\n",
    "quickly decreases than increases (i.e. the mouse blinks).\n",
    "Let's quantify this transient motion after stimulation.\n",
    "Below, we define a utility that takes in a row of data, then computes\n",
    "the relative height of the peak we see in the plots above.\n",
    "We apply this utility to each row of our data then create a new `DataFrame` with\n",
    "the computed values as a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_peak_amp(row):\n",
    "    # get the signal\n",
    "    signal = row[\"timeseries\"]\n",
    "    # get the stimulation times\n",
    "    stim = _time_to_frame(row[\"stim_times\"])\n",
    "    tpre = int(0.1 * 100)\n",
    "    tpost = int(0.4 * 100)\n",
    "    # measure the average signal 0.1 seconds prior to each stimulation\n",
    "    baseline = np.array([np.mean(signal[(t - tpre):t]) for t in stim])\n",
    "    # find the peak (positive or negative) relative the baseline for each stimulation\n",
    "    peak = np.array([max(np.max(signal[t:(t + tpost)] - b),\n",
    "                         np.min(signal[t:(t + tpost)] - b),\n",
    "                         key=abs)\n",
    "                     for t, b in zip(stim, baseline)])\n",
    "\n",
    "    # return the computed peaks as a Series (i.e. column)\n",
    "    return pd.Series({\"peak_amplitude\": peak})\n",
    "\n",
    "peak_amplitude = merge_df.apply(compute_peak_amp, axis=1)\n",
    "\n",
    "motion_df = pd.concat([merge_df, peak_amplitude], axis=1)\n",
    "motion_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have a single number (the peak amplitude) for each stimulation that\n",
    "summarize how much the facial feature changed post-stimulation.\n",
    "Let's use it to see how stimulation amplitude affects the change in facial features.\n",
    "In particular, let's compare the eye height change on the ipsilateral and\n",
    "contralateral sides of the face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = list(set([(date, mouse) for date, mouse, _ in data_keys]))\n",
    "\n",
    "# we will create a separate plot for each session\n",
    "for date, mouse in sessions:\n",
    "    # correctly select the ipsilateral or contralateral side\n",
    "    ipsi_side = CRANIOTOMY_MAP[mouse]\n",
    "    contra_side = \"right\" if ipsi_side == \"left\" else \"left\"\n",
    "    measure = f\"eye-height-{ipsi_side}\"\n",
    "    ipsi_df = motion_df.query(\"date == @date & mouse == @mouse & \"\n",
    "                              \"stim_shank == 'A' & stim_depth == 'A' & \"\n",
    "                              \"measurement_name == @measure\")\n",
    "    measure = f\"eye-height-{contra_side}\"\n",
    "    contra_df = motion_df.query(\"date == @date & mouse == @mouse & \"\n",
    "                                \"stim_shank == 'A' & stim_depth == 'A' & \"\n",
    "                                \"measurement_name == @measure\")\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=2, dpi=300,\n",
    "                           sharey=True, figsize=(8, 4))\n",
    "    # concatenate all the rows togther into one flat x-axis and y-axis vector\n",
    "    # make sure to repeat the stimulation amplitude as many times as the mouse\n",
    "    # was stimulated so the x and y vectors are the same length\n",
    "    ipsi_xs = np.concatenate([np.repeat(amp, len(times))\n",
    "                        for amp, times in zip(ipsi_df[\"stim_amplitude\"].values,\n",
    "                                              ipsi_df[\"peak_amplitude\"].values)], axis=0)\n",
    "    ipsi_ys = np.abs(np.concatenate(ipsi_df[\"peak_amplitude\"].values, axis=0)) * 1000\n",
    "    contra_xs = np.concatenate([np.repeat(amp, len(times))\n",
    "                        for amp, times in zip(contra_df[\"stim_amplitude\"].values,\n",
    "                                              contra_df[\"peak_amplitude\"].values)], axis=0)\n",
    "    contra_ys = np.abs(np.concatenate(contra_df[\"peak_amplitude\"].values, axis=0)) * 1000\n",
    "\n",
    "    # plot the ipsilateral data as individual points\n",
    "    sns.stripplot(x=ipsi_xs, y=ipsi_ys,\n",
    "                  alpha=0.2,\n",
    "                  native_scale=True,\n",
    "                  ax=ax[0])\n",
    "    # plot the ipsilateral data as a mean and standard deviation\n",
    "    sns.pointplot(x=ipsi_xs, y=ipsi_ys,\n",
    "                  linestyle=\"none\",\n",
    "                  marker=\"_\", markersize=8, markeredgewidth=2,\n",
    "                  label=\"Ipsilateral\",\n",
    "                  capsize=1,\n",
    "                  native_scale=True,\n",
    "                  errorbar=(lambda x: (x.mean() - x.std(ddof=1), x.mean() + x.std(ddof=1))),\n",
    "                  legend=False,\n",
    "                  ax=ax[0])\n",
    "\n",
    "    # plot the contralateral data as individual points\n",
    "    sns.stripplot(x=contra_xs, y=contra_ys,\n",
    "                  alpha=0.2,\n",
    "                  native_scale=True,\n",
    "                  ax=ax[1])\n",
    "    # plot the contralateral data as a mean and standard deviation\n",
    "    sns.pointplot(x=contra_xs, y=contra_ys,\n",
    "                  linestyle=\"none\",\n",
    "                  marker=\"_\", markersize=8, markeredgewidth=2,\n",
    "                  label=\"Contralateral\",\n",
    "                  capsize=1,\n",
    "                  native_scale=True,\n",
    "                  errorbar=(lambda x: (x.mean() - x.std(ddof=1), x.mean() + x.std(ddof=1))),\n",
    "                  legend=False,\n",
    "                  ax=ax[1])\n",
    "\n",
    "    sns.despine(fig)\n",
    "    ax[0].legend(frameon=False, loc=\"upper left\")\n",
    "    ax[1].legend(frameon=False, loc=\"upper left\")\n",
    "    ax[0].set_xlabel(\"Stimulation amplitude ($\\mu$A)\")\n",
    "    ax[1].set_xlabel(\"Stimulation amplitude ($\\mu$A)\")\n",
    "    ax[0].set_ylabel(\"Peak amplitude ($\\mu$m)\")\n",
    "    fig.suptitle(\"Change in Eye Height of Post-Stimulation\")\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the ipsilateral side changes correlate with the stimulation amplitude,\n",
    "while the contralateral side does not until the stimulation amplitude is much higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we've only focused on data with all electrodes.\n",
    "Now, let's look at location dependent stimulation.\n",
    "In the cells below, we will generate heatmaps (one for each facial feature and\n",
    "recording date+mouse). The x- and y-axis of heatmaps correspond to the stimulation\n",
    "location, and the color is the average peak amplitude of the given facial feature\n",
    "at a specific stimulation current and location.\n",
    "\n",
    "As you will see, certain facial features respond to certain stimulation locations.\n",
    "To get a sense of how they respond, we will compute a \"center of gravity\"---\n",
    "which is a point in the 2D stimulation space that identifies which location a\n",
    "facial feature responds to most.\n",
    "\n",
    "For now, the `compute_center_of_gravity` function simply returns the average\n",
    "of all the stimulation locations. So, the \"center of gravity\" is dead center in\n",
    "the 2D space. **_Your job is to incorporate the `response` argument to compute\n",
    "the true center of gravity_**. Hint: it should be weighted by the respond in each\n",
    "location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: rewrite the body of this function to compute the true center of gravity\n",
    "# then re-run both cells\n",
    "def compute_center_of_gravity(response, locations):\n",
    "    return locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an equally spaced grid of stimulation locations\n",
    "locations = np.array([[[i, j] for j in range(4)] for i in range(2)])\n",
    "locations = locations + np.array([[[0.5, 0.5]]])\n",
    "# choose a subset of measurements, dates/mice, and amplitudes for plotting\n",
    "measurements = [\"eye-height-ipsi\",\n",
    "                \"eye-height-contra\",\n",
    "                \"mouth-area\",\n",
    "                \"nose-bulge-volume\",\n",
    "                \"cheek-bulge-volume\"]\n",
    "sessions = list(set([(date, mouse) for date, mouse, _ in data_keys]))\n",
    "amplitudes = motion_df.query(\"stim_shank != 'A' & stim_depth != 'A'\").stim_amplitude.unique()\n",
    "\n",
    "# in the loop below, we go to each amplitude, then date and mouse, then measurement\n",
    "# and we extract the average peak amplitude for different stimulation locations\n",
    "data = {amp: {session: {measure: np.zeros((2, 4)) for measure in measurements}\n",
    "              for session in sessions}\n",
    "        for amp in amplitudes}\n",
    "centers = {amp: {session: {measure: np.zeros((2,)) for measure in measurements}\n",
    "                 for session in sessions}\n",
    "           for amp in amplitudes}\n",
    "for amp in amplitudes:\n",
    "    for session in sessions:\n",
    "        date, mouse = session\n",
    "        for measure in measurements:\n",
    "            # loop over the stimulation depth and shank\n",
    "            for row, depth in enumerate((\"U\", \"L\")):\n",
    "                for col, shank in enumerate((\"1\", \"2\", \"3\", \"4\")):\n",
    "                    # select the ipsi/contra side of the facial feature\n",
    "                    # only if it is not a bilateral facial feature\n",
    "                    ipsi_side = CRANIOTOMY_MAP[mouse]\n",
    "                    contra_side = \"right\" if ipsi_side == \"left\" else \"left\"\n",
    "                    _measure = (measure.replace(\"ipsi\", ipsi_side)\n",
    "                                       .replace(\"contra\", contra_side))\n",
    "                    # get the peak amplitude responses\n",
    "                    response = motion_df.query(\n",
    "                        \"date == @date & mouse == @mouse & \"\n",
    "                        \"measurement_name == @_measure & \"\n",
    "                        \"stim_amplitude == @amp & \"\n",
    "                        \"stim_shank == @shank & stim_depth == @depth\"\n",
    "                    )\n",
    "                    # if the specific amplitude, session, measure was not\n",
    "                    # recorded in this experiment, then skip\n",
    "                    if len(response) == 0:\n",
    "                        continue\n",
    "                    # compute the average absolute peak amplitude and add it to\n",
    "                    # the data dictionary\n",
    "                    peak = np.concatenate(response.peak_amplitude.values, axis=0)\n",
    "                    data[amp][session][measure][row, col] = np.mean(np.abs(peak))\n",
    "            # once we have the average peak amplitude for all locations\n",
    "            # compute the center of gravity\n",
    "            centers[amp][session][measure] = compute_center_of_gravity(\n",
    "                data[amp][session][measure], locations\n",
    "            )\n",
    "\n",
    "# create a separate set of plots for each amplitude\n",
    "for amp in amplitudes:\n",
    "    fig, axs = plt.subplots(nrows=len(measurements),\n",
    "                            ncols=len(sessions),\n",
    "                            dpi=300,\n",
    "                            figsize=(4 * len(sessions), 2 * len(measurements)))\n",
    "    cbar_axs = []\n",
    "    for i in range(len(measurements)):\n",
    "        cbar_axs.append(fig.add_axes([0.91, 0.75 - i * 0.16, .01, 0.12]))\n",
    "\n",
    "    for i, measure in enumerate(measurements):\n",
    "        data_min = min(np.min(data[amp][session][measure])\n",
    "                       for session in sessions)\n",
    "        data_max = max(np.max(data[amp][session][measure])\n",
    "                       for session in sessions)\n",
    "        for j, (date, mouse) in enumerate(sessions):\n",
    "            sns.heatmap(data=data[amp][(date, mouse)][measure],\n",
    "                        xticklabels=(\"1\", \"2\", \"3\", \"4\"),\n",
    "                        yticklabels=(\"U\", \"L\"),\n",
    "                        cbar_ax=cbar_axs[i],\n",
    "                        square=True,\n",
    "                        # center=0,\n",
    "                        cmap=sns.color_palette(\"Oranges\", as_cmap=True),\n",
    "                        vmin=data_min,\n",
    "                        vmax=data_max,\n",
    "                        ax=axs[i, j])\n",
    "            sns.scatterplot(x=[centers[amp][(date, mouse)][measure][1]],\n",
    "                            y=[centers[amp][(date, mouse)][measure][0]],\n",
    "                            s=100,\n",
    "                            color=\"black\",\n",
    "                            legend=False,\n",
    "                            ax=axs[i, j])\n",
    "            if i == 0:\n",
    "                axs[i, j].set_title(f\"{mouse} ({date})\")\n",
    "        axs[i, 0].set_ylabel(measure.replace(\"-\", \" \")\n",
    "                                    .capitalize()\n",
    "                                    .replace(\"ipsi\", \"\\n(ipsilateral)\")\n",
    "                                    .replace(\"contra\", \"\\n(contralateral)\"))\n",
    "    fig.supxlabel(\"Shank Position\")\n",
    "    fig.supylabel(\"Shank Depth\")\n",
    "    fig.suptitle(f\"Location-Dependent Change in Facial Features ({amp} $\\mu$A)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the centers alone without the heatmap across stimulation amplitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=len(amplitudes),\n",
    "                        ncols=len(sessions),\n",
    "                        dpi=300,\n",
    "                        figsize=(3.5 * len(sessions), 2 * len(amplitudes)))\n",
    "\n",
    "for i, amp in enumerate(np.sort(amplitudes)):\n",
    "    for j, (date, mouse) in enumerate(sessions):\n",
    "        xs = np.array([centers[amp][(date, mouse)][measure][1]\n",
    "                       for measure in measurements])\n",
    "        ys = np.array([centers[amp][(date, mouse)][measure][0]\n",
    "                       for measure in measurements])\n",
    "        sns.scatterplot(x=xs, y=ys, hue=measurements,\n",
    "                        s=100,\n",
    "                        legend=False,\n",
    "                        ax=axs[i, j])\n",
    "        axs[i, j].set_xlim(0, 4)\n",
    "        axs[i, j].set_ylim(0, 2)\n",
    "        if i == 0:\n",
    "            axs[i, j].set_title(f\"{mouse} ({date})\")\n",
    "        if j == 0:\n",
    "            axs[i, j].set_ylabel(f\"{amp} $\\mu$A\")\n",
    "fig.supxlabel(\"Session\", y=-0.01)\n",
    "fig.supylabel(\"Stimulation Amplitude\", x=-0.01)\n",
    "fig.suptitle(\"Location-Dependent Change in Facial Features\", y=1.01)\n",
    "fig.tight_layout(h_pad=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
